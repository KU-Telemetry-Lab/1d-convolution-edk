// from:  https://stackoverflow.com/questions/15853140/fir-filter-in-cuda-as-a-1d-convolution#32205250
// response by Vitality
#include <stdio.h>
#include <stdlib.h>

#include <time.h>
#include <chrono>



#define CONVOLVE_WIDTH 57
// __constant__ float CONVOLVE_VECTOR[CONVOLVE_WIDTH];

#define RG          10
#define BLOCKSIZE   8
#define NUM_THREADS CONVOLVE_WIDTH + 7

#define ROUND_UP(numer, denom) ((numer+denom-1)/denom)


/****************/
/* CPU FUNCTION */
/****************/
void h_convolution_1D(const float * __restrict__ h_Signal, const float * __restrict__ h_ConvKernel,
                      float * __restrict__ h_Result_CPU, const int N, const int K) {

    for (int i = 0; i < N; i++) {
        float temp = 0.f;
        int N_start_point = i - (K / 2);
        for (int j = 0; j < K; j++) {
          if (N_start_point + j >= 0 && N_start_point + j < N)
            temp += h_Signal[N_start_point+ j] * h_ConvKernel[j];
        }
        h_Result_CPU[i] = temp;
    }
}


static void HandleError( cudaError_t err,
                         const char *file,
                         int line ) {
    if (err != cudaSuccess) {
        printf( "%s in %s at line %d\n", cudaGetErrorString( err ),
                file, line );
        exit( EXIT_FAILURE );
    }
}
#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))

/********************/
/* BASIC GPU KERNEL */
/********************/
__global__ void d_convolution_1D_basic(const float * __restrict__ d_Signal, const float * __restrict__ d_ConvKernel,
                                       float * __restrict__ d_Result_GPU, const int N, const int K) {

    int i = blockIdx.x * blockDim.x + threadIdx.x;
    float temp = 0.f;
    int N_start_point = i - (K / 2);

    for (int j = 0; j < K; j++) {
      if (N_start_point + j >= 0 && N_start_point + j < N)
        temp += d_Signal[N_start_point+ j] * d_ConvKernel[j];
    }
    d_Result_GPU[i] = temp;
}

/***************************/
/* GPU KERNEL WITH CACHING */
/***************************/
__global__ void d_convolution_1D_caching(const float * __restrict__ d_Signal, const float * __restrict__ d_ConvKernel,
                                         float * __restrict__ d_Result_GPU, const int N, const int K) {

    int i = blockIdx.x * blockDim.x + threadIdx.x;

    __shared__ float d_Tile[BLOCKSIZE];

    d_Tile[threadIdx.x] = d_Signal[i];
    __syncthreads();

    float temp = 0.f;
    int N_start_point = i - (K / 2);

    for (int j = 0; j < K; j++) if (N_start_point + j >= 0 && N_start_point + j < N) {
            if ((N_start_point + j >= blockIdx.x * blockDim.x) && (N_start_point + j < (blockIdx.x + 1) * blockDim.x))
                // --- The signal element is in the tile loaded in the shared memory
                temp += d_Tile[threadIdx.x + j - (K / 2)] * d_ConvKernel[j];
            else
                // --- The signal element is not in the tile loaded in the shared memory
                temp += d_Signal[N_start_point + j] * d_ConvKernel[j];
    }
    d_Result_GPU[i] = temp;
}

__global__ void d_convolution_1D_edk (const float * __restrict__ signal, const float * __restrict__ CONVOLVE_VECTOR,
                                      float * __restrict__ result, const int sigLen) {

  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int iLocal = threadIdx.x;

  __shared__ float sigLocal[ NUM_THREADS + CONVOLVE_WIDTH];

  int sigIndex;
  if ( i < sigLen) {
    sigIndex = i - CONVOLVE_WIDTH/2;
    sigLocal[iLocal] = sigIndex < 0 ? 0.0: signal[sigIndex];
    if (iLocal < CONVOLVE_WIDTH) {
      sigIndex = i - CONVOLVE_WIDTH/2 + NUM_THREADS;
      sigLocal[iLocal + NUM_THREADS] = sigIndex >= sigLen ? 0.0: signal[sigIndex];
    }
    __syncthreads();

    float accum = 0.0;
    for (int j=0; j < CONVOLVE_WIDTH; j++) accum += sigLocal[iLocal + j] * CONVOLVE_VECTOR[j];
    result[i] = accum;
  }
}

void edk_debug (const float * signal, const float * CONVOLVE_VECTOR,
                float * result, const int sigLen) {

  float sigLocal[ NUM_THREADS + CONVOLVE_WIDTH];

  for (int threadIdx = 0; threadIdx < NUM_THREADS; threadIdx++)  {
    int i = threadIdx;
    int iLocal = threadIdx;

    int sigIndex;
    sigIndex = i - CONVOLVE_WIDTH/2;
    sigLocal[iLocal] = sigIndex < 0 ? 0.0: signal[sigIndex];
    printf("sigLocal[%d] = %.0f\n", iLocal, signal[sigIndex]);
    if (iLocal < CONVOLVE_WIDTH) {
      sigIndex = i - CONVOLVE_WIDTH/2 + NUM_THREADS;
      sigLocal[iLocal + NUM_THREADS] = sigIndex >= sigLen ? 0.0: signal[sigIndex];
      printf("***sigLocal[%d] = %.0f\n", iLocal + NUM_THREADS, signal[sigIndex]);
    }
  }
  for (int threadIdx = 0; threadIdx < NUM_THREADS; threadIdx++) {
    int i = threadIdx;
    int iLocal = threadIdx;
    float accum = 0.0;
    for (int j=0; j < CONVOLVE_WIDTH; j++) accum += sigLocal[iLocal + j] * CONVOLVE_VECTOR[j];
    result[i] = accum;
    printf("R[%d] == %2.0f\n", i, accum);
  }
  printf("SIGLOC: ");
  for (int j=0; j < NUM_THREADS + CONVOLVE_WIDTH; j++) printf(" %.0f", sigLocal[j]);
  printf("\n");

  printf("Result: ");
  for (int j=0; j < NUM_THREADS; j++) printf(" %2.0f", result[j]);
  printf("\n");
}

/********/
/* MAIN */
/********/
int main(){

  using clock = std::chrono::steady_clock;

  clock::time_point startTime;
  clock::time_point endTime;
  clock::duration allTime;
  uint64_t timeMsec;

  //    const int N = 15;           // --- Signal length
  //    const int K = 5;            // --- Convolution kernel length
    const int N = 1024 * 1024 * 32;           // --- Signal length
    const int K = CONVOLVE_WIDTH;            // --- Convolution kernel length

    float *h_Signal         = (float *)malloc(N * sizeof(float));
    float *h_Result_CPU     = (float *)malloc(N * sizeof(float));
    float *h_Result_DEBUG   = (float *)malloc(N * sizeof(float));
    float *h_Result_GPU     = (float *)malloc(N * sizeof(float));
    float *h_ConvKernel     = (float *)malloc(K * sizeof(float));

    float *d_Signal;
    HANDLE_ERROR(cudaMalloc(&d_Signal,     N * sizeof(float)));
    float *d_Result_GPU;
    HANDLE_ERROR(cudaMalloc(&d_Result_GPU, N * sizeof(float)));
    float *d_ConvKernel;
    HANDLE_ERROR(cudaMalloc(&d_ConvKernel, K * sizeof(float)));

    for (int i=0; i < N; i++) { h_Signal[i] = (float)(rand() % RG); }
    for (int i=0; i < K; i++) { h_ConvKernel[i] = (float)(rand() % RG); }

    HANDLE_ERROR(cudaMemcpy(d_Signal,      h_Signal,       N * sizeof(float), cudaMemcpyHostToDevice));
    HANDLE_ERROR(cudaMemcpy(d_ConvKernel,  h_ConvKernel,   K * sizeof(float), cudaMemcpyHostToDevice));


    h_convolution_1D(h_Signal, h_ConvKernel, h_Result_CPU, N, K);

    d_convolution_1D_basic<<<ROUND_UP(N, BLOCKSIZE), BLOCKSIZE>>>(d_Signal, d_ConvKernel, d_Result_GPU, N, K);
    HANDLE_ERROR(cudaPeekAtLastError());
    HANDLE_ERROR(cudaDeviceSynchronize());

    HANDLE_ERROR(cudaMemcpy(h_Result_GPU, d_Result_GPU, N * sizeof(float), cudaMemcpyDeviceToHost));

    for (int i = 0; i < N; i++) {
      if (h_Result_CPU[i] != h_Result_GPU[i]) {
        printf("mismatch2 at %d, cpu: %.2f, gpu %.2f\n", i, h_Result_CPU[i], h_Result_GPU[i]);
        return 1;
      }
    }
    printf("Test basic passed\n");

    d_convolution_1D_caching<<<ROUND_UP(N, BLOCKSIZE), BLOCKSIZE>>>(d_Signal, d_ConvKernel, d_Result_GPU, N, K);
    HANDLE_ERROR(cudaPeekAtLastError());
    HANDLE_ERROR(cudaDeviceSynchronize());

    HANDLE_ERROR(cudaMemcpy(h_Result_GPU, d_Result_GPU, N * sizeof(float), cudaMemcpyDeviceToHost));

    for (int i = 0; i < N; i++) {
      if (h_Result_CPU[i] != h_Result_GPU[i]) {
        printf("mismatch2 at %d, cpu: %.2f, gpu %.2f\n", i, h_Result_CPU[i], h_Result_GPU[i]);
        return 1;}
    }
    printf("Test caching passed\n");

    //    edk_debug(h_Signal,  h_ConvKernel, h_Result_DEBUG, N);

    d_convolution_1D_edk<<<ROUND_UP(N, NUM_THREADS), NUM_THREADS>>>(d_Signal,  d_ConvKernel, d_Result_GPU, N);
    HANDLE_ERROR(cudaPeekAtLastError());
    HANDLE_ERROR(cudaDeviceSynchronize());

    HANDLE_ERROR(cudaMemcpy(h_Result_GPU, d_Result_GPU, N * sizeof(float), cudaMemcpyDeviceToHost));

    for (int i = 0; i < N; i++) {
      if (h_Result_CPU[i] != h_Result_GPU[i]) {
        printf("mismatch2 at %d, cpu: %.2f, gpu %.2f\n", i, h_Result_CPU[i], h_Result_GPU[i]);
        return 1;}
    }
    printf("Test edk version passed\n");

}
